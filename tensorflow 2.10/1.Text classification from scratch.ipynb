{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5951738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string, re\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c13aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "b'I\\'ve seen tons of science fiction from the 70s; some horrendously bad, and others thought provoking and truly frightening. Soylent Green fits into the latter category. Yes, at times it\\'s a little campy, and yes, the furniture is good for a giggle or two, but some of the film seems awfully prescient. Here we have a film, 9 years before Blade Runner, that dares to imagine the future as somthing dark, scary, and nihilistic. Both Charlton Heston and Edward G. Robinson fare far better in this than The Ten Commandments, and Robinson\\'s assisted-suicide scene is creepily prescient of Kevorkian and his ilk. Some of the attitudes are dated (can you imagine a filmmaker getting away with the \"women as furniture\" concept in our oh-so-politically-correct-90s?), but it\\'s rare to find a film from the Me Decade that actually can make you think. This is one I\\'d love to see on the big screen, because even in a widescreen presentation, I don\\'t think the overall scope of this film would receive its due. Check it out.'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "raw_train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size, validation_split=0.2, subset=\"training\", seed=1337)\n",
    "raw_val_ds  =  keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size, validation_split=0.2, subset=\"validation\", seed=1337)\n",
    "raw_test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)\n",
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(1):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0158fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  10    7  240 ...    0    0    0]\n",
      " [  10   17   13 ...    0    0    0]\n",
      " [  89   76   69 ...    0    0    0]\n",
      " ...\n",
      " [1196   50   11 ...    0    0    0]\n",
      " [  47   13  136 ...    0    0    0]\n",
      " [  11  727  159 ...    0    0    0]], shape=(32, 500), dtype=int64)\n",
      "tf.Tensor([1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
    "\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "vectorize_layer = keras.layers.TextVectorization(standardize=custom_standardization, max_tokens=max_features, output_sequence_length=sequence_length)\n",
    "vectorize_layer.adapt(raw_train_ds.map(lambda x,y:x))\n",
    "\n",
    "def vecrorize_text(text, label):\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "train_ds = raw_train_ds.map(vecrorize_text).cache().prefetch(buffer_size=10)\n",
    "val_ds = raw_val_ds.map(vecrorize_text).cache().prefetch(buffer_size=10)\n",
    "test_ds = raw_test_ds.map(vecrorize_text).cache().prefetch(buffer_size=10)\n",
    "for texts,labels in train_ds.take(1):\n",
    "    print(texts)\n",
    "    print(labels)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "498c82b1",
   "metadata": {},
   "source": [
    "我们从每一步的输入和输出形状（shape）来分析代码。\n",
    "\n",
    "```python\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "```\n",
    "\n",
    "- 这行代码定义了一个输入层，输入的 `shape` 是 `(None,)`，表示输入序列的长度可以是任意的。`dtype=\"int64\"` 表示输入数据的类型是整数。这一层的输出 `shape` 是 `(batch_size, sequence_length)`，其中 `sequence_length` 是输入的实际序列长度。\n",
    "\n",
    "```python\n",
    "x = keras.layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "```\n",
    "\n",
    "- 这一层是嵌入层（Embedding layer），它将输入的整数序列转换为密集的向量表示。`max_features` 表示词汇表的大小，`embedding_dim` 表示每个词嵌入向量的维度。输出 `shape` 是 `(batch_size, sequence_length, embedding_dim)`，其中 `embedding_dim` 是嵌入向量的维度。\n",
    "\n",
    "```python\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "```\n",
    "\n",
    "- Dropout 层用于在训练期间随机丢弃一部分神经元来防止过拟合。Dropout 层不会改变 `shape`，因此输出 `shape` 仍然是 `(batch_size, sequence_length, embedding_dim)`。\n",
    "\n",
    "```python\n",
    "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "```\n",
    "\n",
    "- 这是一维卷积层（Conv1D layer）。`128` 表示卷积核的数量，也就是输出通道数。`7` 表示卷积核的大小（filter size）。`strides=3` 表示卷积核的步幅为3。`padding=\"valid\"` 表示不进行填充。输出的 `shape` 将是 `(batch_size, new_sequence_length, 128)`，其中 `new_sequence_length` 由以下公式计算：\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "总结一下各个步骤的 `shape` 变化：\n",
    "\n",
    "1. `inputs`：`(batch_size, sequence_length)`\n",
    "2. `Embedding`：`(batch_size, sequence_length, embedding_dim)`\n",
    "3. `Dropout`：`(batch_size, sequence_length, embedding_dim)`\n",
    "4. `Conv1D`：`(batch_size, new_sequence_length, 128)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e07139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e71d2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = keras.layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x) # (B, 165, 128)\n",
    "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x) # (B, 53, 128)\n",
    "x = keras.layers.GlobalMaxPooling1D()(x)  # (B, 128)  沿着时间步维度（即第二个维度，长度为 53）进行最大池化操作。\n",
    "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "model = keras.Model(inputs, predictions)\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "970a5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.5130 - binary_accuracy: 0.7035 - val_loss: 0.3061 - val_binary_accuracy: 0.8704\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2247 - binary_accuracy: 0.9122 - val_loss: 0.3440 - val_binary_accuracy: 0.8604\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1161 - binary_accuracy: 0.9577 - val_loss: 0.4223 - val_binary_accuracy: 0.8712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e00f6a0460>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=3) # 4.2G-4.4G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41aa0736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 8ms/step - loss: 0.4301 - binary_accuracy: 0.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43008673191070557, 0.8630800247192383]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d5532",
   "metadata": {},
   "source": [
    "# 直接以字符串为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa3c5864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4301 - accuracy: 0.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43008673191070557, 0.8630800247192383]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
    "indices = vectorize_layer(inputs)\n",
    "outputs = model(indices)\n",
    "end_to_end_model = keras.Model(inputs, outputs)\n",
    "end_to_end_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "end_to_end_model.evaluate(raw_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50c116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed20dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2.10.0-py-3.10",
   "language": "python",
   "name": "tf-gpu-2.10.0-py-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
