本文正在参加「Python主题月」，详情查看 [活动链接](https://juejin.cn/post/6979532761954533390/)

## 什么是词法分析？

词法分析就是利用计算机对自然语言的形态进行分析，判断词的结构和类别等，具体到实际的项目任务来说，就是分词并对每个词进行分类，包括：分词、词性标注、实体识别三个任务。这三个任务的难度是逐渐递增的，如下举例：

	原文：百度是一家高科技公司
	分词：百度 是 一家 高科技 公司
	词性标注：百度/n 是/v 一家/m 高科技/n 公司/n
	实体识别：百度/ORG 是/v 一家/m 高科技/n 公司/n

## 词法分析有什么用？
	
* 用字来表述含义往往信息不足，且因为汉语的复杂性产生很多歧义，所以选用词作为自然语言处理中表述含义的基本单位
* 以搜索引擎的角度来说，用选用词粒度处理自然语言相关任务，是准确率和召回率的均衡
* 词法分析是自然语言处理最基础最基本的任务，是上层任务的保证


## 词法分析的应用

* 词法分词最常见的就是应用到搜索引擎，如百度
* 搜索 Top1 问答，如搜索“姚明的妻子”可以直接返回“叶莉”，当然这里还用到了知识图谱，但是基本的底层任务还是词法分析
* 通过智能语音助手去控制热水器加热到 50 度，需要将语言转化为文本，然后识别出文本的关键实体和命令
* 对话问答，在进行人机交流过程中互相理解表达意思的时候，也需要词法分析
* 实体抽取，如复杂快递地址中抽取人名，手机号，地址等信息

## 词法分析的技术发展

1.基于词典
	
* 	字符串匹配：前向/后向最大匹配等，代表工具有 IK 分词，优点是速度快，容易理解，缺点是无法解决歧义和未登陆词问题。
* 	统计语言模型：基于词典构造有向无环图计算最大概率路径，代表应用有 n-gram、 jieba 等，优点是可以通过概率缓解歧义问题，但是仍然无法解决未登陆词问题。


2.基于序列标注

* 	统计方法：HMM、CRF 等
* 	深度学习方法：LSTM-CRF、FLAT 等，目前 LSTM-CRF 是最常用的方法，当然也可以将 LSTM 换成预训练模型。

3.性能对比（MSR 数据集）


|  算法   | 精确率  | 召回率 | F1 |
|  ----  | ----  | ----  | ----  |
| 最长匹配  | 89.41 | 94.64 | 91.95 ｜
| 统计语言模型  | 92.38| 96.70| 94.49 |
| CRF | 96.86 | 96.64 | 96.75 |
|LSTM-CRF|97.20|97.30|97.30|


其实从结果的对比中来看，词典匹配的方法也不算差，所以在某些对准确率要求不高速度较快的场景下仍然可以使用；而表现最好的就是 LSTM-CRF ，各项指标都是最好的，说明该模型的使用价值也很高。

## 任务展示
目前百度的自然语言处理貌似性能不错，刚刚在大赛中获得了不错的成绩，两金一银的成绩是相当能打了，希望再接再厉吧。详情见此文介绍，[传送走你](https://blog.csdn.net/qq_40247584/article/details/118554433?spm=1001.2014.3001.5501)。

这里用 jieba 来进行任务的展示。先安装好包：

	pip install jieba
	
1.分词任务

	import jieba
	seg_str = "我是个好孩子"
	print("/".join(jieba.lcut(seg_str)))    
	
打印结果：

	我/是/个/好孩子
2.词性标注
	
	import jieba.posseg as pseg
	words =pseg.cut("我是个好孩子")
	print(" ".join([w.word+'/'+w.flag for w in words]))
打印结果：

	我/r 是/v 个/q 好孩子/n
3.实体识别

jieba 目前还不能进行实体识别，这里就简单举例：
	
	输入原文：百度是一家高科技公司
	实体识别：百度/ORG 是/v 一家/m 高科技/n 公司/n