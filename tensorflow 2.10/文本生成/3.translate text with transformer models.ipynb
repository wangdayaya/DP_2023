{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b75f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import einops\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow as tf\n",
    "gpu_list = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpu_list) > 0:\n",
    "    for gpu in gpu_list:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e) \n",
    "else:\n",
    "    print(\"Got no gpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e77d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf-gpu-2.10.0-py-3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b8ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d65cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   2  120   85  979  103   95 4160   16    3    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]], shape=(1, 73), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[   2   96   80   37  622   74 3456 3921   15    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 81), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[  96   80   37  622   74 3456 3921   15    3    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 81), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "MAX_TOKENS=128\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',  with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(f'{model_name}.zip', f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip', cache_dir='.', cache_subdir='', extract=True )\n",
    "tokenizers = tf.saved_model.load(model_name)\n",
    "\n",
    "def prepare_batch(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    pt = pt[:, :MAX_TOKENS].to_tensor()\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en[:, :MAX_TOKENS+1]\n",
    "    en_inputs = en[:,:-1].to_tensor()\n",
    "    en_labels = en[:, 1:].to_tensor()\n",
    "    return (pt, en_inputs), en_labels\n",
    "\n",
    "train_batches =  train_examples.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(prepare_batch, tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_batches =  val_examples.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(prepare_batch, tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "for (e,i),o in train_batches.take(1):\n",
    "    print(e[:1])\n",
    "    print(i[:1])\n",
    "    print(o[:1])"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "031c6470",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f238b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "    positions = np.arange(length)[:, np.newaxis]   # 位置 (length, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth   # 深度 (1, depth)\n",
    "    angle_rates = 1 / (10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "#     pos_encoding = np.zeros((length, depth * 2))\n",
    "#     pos_encoding[:, 0::2] = np.sin(angle_rads)  # 2i: 偶数位置\n",
    "#     pos_encoding[:, 1::2] = np.cos(angle_rads)  # 2i+1: 奇数位置\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "    \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, : length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e7a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497265d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae06de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(query=x, key=context, value=context, return_attention_scores=True)\n",
    "        self.last_attn_scores = attn_scores\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(query=x, value=x, key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(query=x, value=x, key=x, use_causal_mask=True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5357324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = GlobalSelfAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_embedding = PositionEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.enc_layers = [EncoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x =self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e90c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.causal_self_attention = CausalSelfAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.cross_attention = CrossAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.causal_self_attention(x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_embedding = PositionEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate) for _ in range(num_layers)]\n",
    "        self.last_attn_scores = None\n",
    "    \n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c78d835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 15, 512), dtype=float32, numpy=\n",
       "array([[[ 0.74893034, -1.6052595 , -0.3994048 , ...,  1.963297  ,\n",
       "         -1.6808728 , -0.13937518],\n",
       "        [ 1.8466887 , -0.85400987,  0.5228292 , ...,  2.0004137 ,\n",
       "         -1.6961007 , -0.1371011 ],\n",
       "        [ 1.9615678 , -0.69911665,  0.7384652 , ...,  2.06872   ,\n",
       "         -1.4438744 , -0.09579261],\n",
       "        ...,\n",
       "        [ 0.37530485, -2.0800292 , -0.79535043, ...,  2.203009  ,\n",
       "         -0.92917895,  0.27189368],\n",
       "        [ 1.3792925 , -1.4013275 , -0.23600182, ...,  2.1121204 ,\n",
       "         -0.8000585 ,  0.28068957],\n",
       "        [ 1.8966008 , -0.7115123 ,  0.66725963, ...,  1.950827  ,\n",
       "         -0.8372355 ,  0.20123897]],\n",
       "\n",
       "       [[ 0.74893034, -1.6052595 , -0.3994048 , ...,  1.963297  ,\n",
       "         -1.6808728 , -0.13937518],\n",
       "        [ 1.8466887 , -0.85400987,  0.5228292 , ...,  2.0004137 ,\n",
       "         -1.6961007 , -0.1371011 ],\n",
       "        [ 1.9615678 , -0.69911665,  0.7384652 , ...,  2.06872   ,\n",
       "         -1.4438744 , -0.09579261],\n",
       "        ...,\n",
       "        [ 0.37530485, -2.0800292 , -0.79535043, ...,  2.203009  ,\n",
       "         -0.92917895,  0.27189368],\n",
       "        [ 1.3792925 , -1.4013275 , -0.23600182, ...,  2.1121204 ,\n",
       "         -0.8000585 ,  0.28068957],\n",
       "        [ 1.8966008 , -0.7115123 ,  0.66725963, ...,  1.950827  ,\n",
       "         -0.8372355 ,  0.20123897]],\n",
       "\n",
       "       [[ 0.74893034, -1.6052595 , -0.3994048 , ...,  1.963297  ,\n",
       "         -1.6808728 , -0.13937518],\n",
       "        [ 1.8466887 , -0.85400987,  0.5228292 , ...,  2.0004137 ,\n",
       "         -1.6961007 , -0.1371011 ],\n",
       "        [ 1.9615678 , -0.69911665,  0.7384652 , ...,  2.06872   ,\n",
       "         -1.4438744 , -0.09579261],\n",
       "        ...,\n",
       "        [ 0.37530485, -2.0800292 , -0.79535043, ...,  2.203009  ,\n",
       "         -0.92917895,  0.27189368],\n",
       "        [ 1.3792925 , -1.4013275 , -0.23600182, ...,  2.1121204 ,\n",
       "         -0.8000585 ,  0.28068957],\n",
       "        [ 1.8966008 , -0.7115123 ,  0.66725963, ...,  1.950827  ,\n",
       "         -0.8372355 ,  0.20123897]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(num_heads=1, num_layers=1, d_model=512, dff=2048, vocab_size=tokenizers.en.get_vocab_size())\n",
    "context=tf.constant(shape=(3,10,256), value=1.)\n",
    "x = tf.constant(shape=(3,15), value=1.)\n",
    "decoder(x, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a10885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=input_vocab_size, dropout_rate=dropout_rate)\n",
    "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=target_vocab_size, dropout_rate=dropout_rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        x = self.decoder(x , context)\n",
    "        logits = self.final_layer(x)\n",
    "        try:\n",
    "            del logits._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        return logits\n",
    "    \n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff,input_vocab_size=tokenizers.pt.get_vocab_size().numpy(), target_vocab_size=tokenizers.en.get_vocab_size(), dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96adfdaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "810/810 [==============================] - 39s 43ms/step - loss: 6.5996 - masked_accuracy: 0.1469 - val_loss: 5.0464 - val_masked_accuracy: 0.2479\n",
      "Epoch 2/20\n",
      "810/810 [==============================] - 55s 67ms/step - loss: 4.5725 - masked_accuracy: 0.2976 - val_loss: 4.0441 - val_masked_accuracy: 0.3606\n",
      "Epoch 3/20\n",
      "810/810 [==============================] - 45s 56ms/step - loss: 3.8208 - masked_accuracy: 0.3799 - val_loss: 3.4296 - val_masked_accuracy: 0.4349\n",
      "Epoch 4/20\n",
      "810/810 [==============================] - 33s 41ms/step - loss: 3.2628 - masked_accuracy: 0.4421 - val_loss: 3.0187 - val_masked_accuracy: 0.4844\n",
      "Epoch 5/20\n",
      "810/810 [==============================] - 35s 43ms/step - loss: 2.8651 - masked_accuracy: 0.4871 - val_loss: 2.7249 - val_masked_accuracy: 0.5195\n",
      "Epoch 6/20\n",
      "810/810 [==============================] - 32s 40ms/step - loss: 2.5505 - masked_accuracy: 0.5261 - val_loss: 2.4583 - val_masked_accuracy: 0.5528\n",
      "Epoch 7/20\n",
      "810/810 [==============================] - 43s 53ms/step - loss: 2.2867 - masked_accuracy: 0.5598 - val_loss: 2.3265 - val_masked_accuracy: 0.5736\n",
      "Epoch 8/20\n",
      "810/810 [==============================] - 58s 72ms/step - loss: 2.0992 - masked_accuracy: 0.5849 - val_loss: 2.2397 - val_masked_accuracy: 0.5868\n",
      "Epoch 9/20\n",
      "810/810 [==============================] - 59s 72ms/step - loss: 1.9478 - masked_accuracy: 0.6059 - val_loss: 2.1879 - val_masked_accuracy: 0.5976\n",
      "Epoch 10/20\n",
      "810/810 [==============================] - 49s 60ms/step - loss: 1.8316 - masked_accuracy: 0.6233 - val_loss: 2.1195 - val_masked_accuracy: 0.6071\n",
      "Epoch 11/20\n",
      "810/810 [==============================] - 33s 41ms/step - loss: 1.7360 - masked_accuracy: 0.6370 - val_loss: 2.1123 - val_masked_accuracy: 0.6145\n",
      "Epoch 12/20\n",
      "810/810 [==============================] - 33s 40ms/step - loss: 1.6558 - masked_accuracy: 0.6488 - val_loss: 2.0967 - val_masked_accuracy: 0.6142\n",
      "Epoch 13/20\n",
      "810/810 [==============================] - 33s 41ms/step - loss: 1.5808 - masked_accuracy: 0.6599 - val_loss: 2.0620 - val_masked_accuracy: 0.6217\n",
      "Epoch 14/20\n",
      "810/810 [==============================] - 55s 68ms/step - loss: 1.5184 - masked_accuracy: 0.6701 - val_loss: 2.0440 - val_masked_accuracy: 0.6241\n",
      "Epoch 15/20\n",
      "810/810 [==============================] - 58s 72ms/step - loss: 1.4626 - masked_accuracy: 0.6783 - val_loss: 2.0348 - val_masked_accuracy: 0.6265\n",
      "Epoch 16/20\n",
      "810/810 [==============================] - 37s 46ms/step - loss: 1.4120 - masked_accuracy: 0.6859 - val_loss: 2.0390 - val_masked_accuracy: 0.6281\n",
      "Epoch 17/20\n",
      "810/810 [==============================] - 33s 41ms/step - loss: 1.3691 - masked_accuracy: 0.6929 - val_loss: 2.0426 - val_masked_accuracy: 0.6277\n",
      "Epoch 18/20\n",
      "810/810 [==============================] - 33s 40ms/step - loss: 1.3265 - masked_accuracy: 0.6998 - val_loss: 2.0591 - val_masked_accuracy: 0.6268\n",
      "Epoch 19/20\n",
      "810/810 [==============================] - 33s 40ms/step - loss: 1.2852 - masked_accuracy: 0.7061 - val_loss: 2.0646 - val_masked_accuracy: 0.6319\n",
      "Epoch 20/20\n",
      "810/810 [==============================] - 32s 40ms/step - loss: 1.2509 - masked_accuracy: 0.7126 - val_loss: 2.0662 - val_masked_accuracy: 0.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250140e14e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "    mask = label != 0\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2=0.98, epsilon=1e-9)\n",
    "transformer.compile(loss = masked_loss, optimizer=optimizer, metrics=[masked_accuracy])\n",
    "transformer.fit(train_batches, epochs=20, validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4890cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, tokenizers, transformer):\n",
    "        self.tokenizers = tokenizers\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "        assert isinstance(sentence, tf.Tensor)\n",
    "        if len(sentence.shape) == 0:\n",
    "            sentence = sentence[tf.newaxis]\n",
    "        sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "        encoder_input = sentence\n",
    "        start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "        start = start_end[0][tf.newaxis]\n",
    "        end = start_end[1][tf.newaxis]\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        output_array = output_array.write(0 , start)\n",
    "        for i in tf.range(max_length):\n",
    "            output = tf.transpose(output_array.stack())\n",
    "            predictions = self.transformer([encoder_input, output], training=False)\n",
    "            predictions = predictions[:, -1:, :]\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "            output_array = output_array.write(i+1, predicted_id[0])\n",
    "            if predicted_id == end:\n",
    "                break\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        text = tokenizers.en.detokenize(output)[0]\n",
    "        tokens = tokenizers.en.lookup(output)[0]\n",
    "        self.transformer([encoder_input, output[:, :-1]], training=False)\n",
    "        attention_weights = self.transformer.decoder.last_attn_scores\n",
    "        return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ade72a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : este é um problema que temos que resolver.\n",
      "Prediction     : this is a problem that we have to solve .\n",
      "Ground truth   : this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(tokenizers, transformer)\n",
    "def print_translation(sentence, tokens, ground_truth):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "    print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
    "    \n",
    "sentence = 'este é um problema que temos que resolver.'\n",
    "ground_truth = 'this is a problem we have to solve .'\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(tf.constant(sentence))\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3626ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translators(tf.Module):\n",
    "    def __init__(self, tokenizers, transformer):\n",
    "        self.tokenizers = tokenizers\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def __call__(self, sentences, max_length=MAX_TOKENS):\n",
    "        assert isinstance(sentences, tf.Tensor)\n",
    "        batch_size = tf.shape(sentences)[0]\n",
    "        sentences = self.tokenizers.pt.tokenize(sentences).to_tensor()\n",
    "        encoder_input = sentences\n",
    "        start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "        start = tf.fill([batch_size, 1], start_end[0])\n",
    "        end = start_end[1]\n",
    "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        output_array = output_array.write(0, start)\n",
    "        for i in tf.range(max_length):\n",
    "            output = tf.transpose(output_array.stack(), perm=[1, 0, 2])\n",
    "            predictions = self.transformer([encoder_input, tf.squeeze(output, axis=-1)], training=False)  # [B,1,V]\n",
    "            predictions = predictions[:, -1:, :]\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "            done |= predicted_id == end\n",
    "            predicted_id = tf.where(done, tf.constant(0, dtype=tf.int64), predicted_id)  # [B, 1]\n",
    "            output_array = output_array.write(i+1, predicted_id)\n",
    "            if tf.reduce_all(done):\n",
    "                break\n",
    "        \n",
    "        output = tf.transpose(output_array.stack(), perm=[1, 0, 2])\n",
    "        output = tf.squeeze(output, axis=-1)  # Remove the last dimension\n",
    "        \n",
    "        text = self.tokenizers.en.detokenize(output)\n",
    "        tokens = self.tokenizers.en.lookup(output)\n",
    "        \n",
    "        return text, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "81ab0470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : este é um problema que temos que resolver.\n",
      "Prediction     : this is a problem that we have to solve .\n",
      "Ground truth   : this is a problem we have to solve .\n",
      "\n",
      "\n",
      "Input:         : os meus vizinhos ouviram sobre esta ideia.\n",
      "Prediction     : my neighbors heard about this idea .\n",
      "Ground truth   : and my neighboring homes heard about this idea .\n",
      "\n",
      "\n",
      "Input:         : vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Prediction     : so i ' m going to be very rapidly in sharing some of the magic stories that happened .\n",
      "Ground truth   : so i'll just share with you some stories very quickly of some magical things that have happened.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translators = Translators(tokenizers, transformer)\n",
    " \n",
    "sentences = [ 'este é um problema que temos que resolver.',  # 'this is a problem we have to solve .'\n",
    " 'os meus vizinhos ouviram sobre esta ideia.',  # 'and my neighboring homes heard about this idea .'\n",
    "  'vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.' #\"so i'll just share with you some stories very quickly of some magical things that have happened.\"\n",
    "  ]\n",
    "ground_truths = ['this is a problem we have to solve .', 'and my neighboring homes heard about this idea .', \"so i'll just share with you some stories very quickly of some magical things that have happened.\"]\n",
    "translated_text, translated_tokens = translators( tf.constant(sentences) )\n",
    "def print_translation(sentences, preds, ground_truths):\n",
    "    for s,t,g in zip(sentences, preds, ground_truths):\n",
    "        print(f'{\"Input:\":15s}: {s}')\n",
    "        print(f'{\"Prediction\":15s}: {t.numpy().decode(\"utf-8\")}')\n",
    "        print(f'{\"Ground truth\":15s}: {g}')\n",
    "        print('\\n')\n",
    "print_translation(sentences, translated_text, ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47335ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63085df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749c1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2.10.0-py-3.10",
   "language": "python",
   "name": "tf-gpu-2.10.0-py-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
