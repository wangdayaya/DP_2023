# conda 创建虚拟环境
创建虚拟环境，python 需要使用 3.11 的版本
```
conda create -n tg-webui python=3.11
```
进入虚拟环境 
```
conda activate tg-webui
```

在[ pytorch 官网](https://pytorch.org/get-started/locally/)找到适合自己 cuda 版本的 pytorch 安装命令，前提是要配置好适合自己显卡的 CUDA 环境，我这里 CUDA 是 11.8 ，已经提前安装好了，如果还不会可以参考我的[安装教程](https://juejin.cn/post/6844904179308183560)，我使用的命令如下：
```
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```



不同的操作系统的安装命令可以参考下面的图表内容，也可以直接去[官网](<https://pytorch.org/get-started/locally/>)
![image.png](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/857d1974c52a4c8b87a666bb8678d3ad~tplv-73owjymdk6-watermark.image?policy=eyJ2bSI6MywidWlkIjoiNTM2MjE3NDA1ODk1MTQ5In0%3D&rk3s=e9ecf3d6&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1720666777&x-orig-sign=qrB42GI7QXRFtHmxeNefLFTa720%3D)



# clone 项目安装 requirements
从官网克隆整个项目
```
git clone https://github.com/oobabooga/text-generation-webui
```
然后进入这个文件夹中安装 requirements.txt ，各个操作系统的安装文件不一样，请自行选择。


![image.png](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/c37a85b2bb5248f69e28e6edbe48aaf0~tplv-73owjymdk6-watermark.image?policy=eyJ2bSI6MywidWlkIjoiNTM2MjE3NDA1ODk1MTQ5In0%3D&rk3s=e9ecf3d6&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1720666789&x-orig-sign=VlXMwH6nYSRlG6ygOW6PkTaUZPM%3D)

我这里是 windows 操作系统，Nvidia 显卡，所以使用下面的安装命令。

```
pip install -r requirements.txt
```
这里需要注意 requirements.txt 最后一些无关的包（如下所示）删除即可，否则会引发不必要的错误

```
# llama-cpp-python (CPU only, AVX2)
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.81+cpuavx2-cp311-cp311-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.11"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.81+cpuavx2-cp310-cp310-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.10"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.81+cpuavx2-cp311-cp311-win_amd64.whl; platform_system == "Windows" and python_version == "3.11"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.81+cpuavx2-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"

# llama-cpp-python (CUDA, no tensor cores)
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.81+cu121-cp311-cp311-win_amd64.whl; platform_system == "Windows" and python_version == "3.11"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.81+cu121-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.81+cu121-cp311-cp311-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.11"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.81+cu121-cp310-cp310-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.10"

# llama-cpp-python (CUDA, tensor cores)
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.81+cu121-cp311-cp311-win_amd64.whl; platform_system == "Windows" and python_version == "3.11"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.81+cu121-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.81+cu121-cp311-cp311-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.11"
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.81+cu121-cp310-cp310-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.10"

# CUDA wheels
https://github.com/oobabooga/exllamav2/releases/download/v0.1.6/exllamav2-0.1.6+cu121.torch2.2.2-cp311-cp311-win_amd64.whl; platform_system == "Windows" and python_version == "3.11"
https://github.com/oobabooga/exllamav2/releases/download/v0.1.6/exllamav2-0.1.6+cu121.torch2.2.2-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"
https://github.com/oobabooga/exllamav2/releases/download/v0.1.6/exllamav2-0.1.6+cu121.torch2.2.2-cp311-cp311-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.11"
https://github.com/oobabooga/exllamav2/releases/download/v0.1.6/exllamav2-0.1.6+cu121.torch2.2.2-cp310-cp310-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.10"
https://github.com/oobabooga/exllamav2/releases/download/v0.1.6/exllamav2-0.1.6-py3-none-any.whl; platform_system == "Linux" and platform_machine != "x86_64"
https://github.com/oobabooga/flash-attention/releases/download/v2.5.9.post1/flash_attn-2.5.9.post1+cu122torch2.2.2cxx11abiFALSE-cp311-cp311-win_amd64.whl; platform_system == "Windows" and python_version == "3.11"
https://github.com/oobabooga/flash-attention/releases/download/v2.5.9.post1/flash_attn-2.5.9.post1+cu122torch2.2.2cxx11abiFALSE-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"
https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.9.post1/flash_attn-2.5.9.post1+cu122torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.11"
https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.9.post1/flash_attn-2.5.9.post1+cu122torch2.2cxx11abiFALSE-cp310-cp310-linux_x86_64.whl; platform_system == "Linux" and platform_machine == "x86_64" and python_version == "3.10"
autoawq==0.2.5; platform_system == "Linux" or platform_system == "Windows"
```




看到下面的日志内容说明成功安装。

![image.png](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/fc682bb363d74e6aa446a19ed3199860~tplv-73owjymdk6-watermark.image?policy=eyJ2bSI6MywidWlkIjoiNTM2MjE3NDA1ODk1MTQ5In0%3D&rk3s=e9ecf3d6&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1720666914&x-orig-sign=cm5NcXryPd43OUKa5839Pe0sLR8%3D)

# 启动服务

控制台运行 server.py 启动服务
```
 python .\server.py
 ```
 当你看到下面的日志打印，就说明启动成功了，访问给出来的 url ： http://127.0.0.1:7860  即刻开始使用。
<p align=center><img src="https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/dca83f02d4d247f3be971fa7dd0988bf~tplv-73owjymdk6-watermark.image?policy=eyJ2bSI6MywidWlkIjoiNTM2MjE3NDA1ODk1MTQ5In0%3D&rk3s=e9ecf3d6&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1720666975&x-orig-sign=Z5CT3MGD4ke27BkPFtHU64mVprI%3D" alt="image.png"  /></p>

我们这里虽然可以启动成功，但是还没有配置可用的模型，我们将下载好的完整的 Qwen2-7B 模型，放到  text-generation-webui\models 目录下面，然后切换到 Model 页面，在 Model 框中会显示出来你放的各种模型名字，然后点击 Load 等待加载即可，加载完成即可切换到其他页面进行愉快的玩耍了。

![image.png](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/71d1fa299ba54a1a945f5d4bddc3ed26~tplv-73owjymdk6-watermark.image?policy=eyJ2bSI6MywidWlkIjoiNTM2MjE3NDA1ODk1MTQ5In0%3D&rk3s=e9ecf3d6&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1720667690&x-orig-sign=84RtX3BiVDuIDb3PNFzlSkaombM%3D)

如果在此步遇到如下问题 DLL load failed while importing flash_attn_2_cuda: The specified module could not be found，不要紧张，你只需要检查两个地方：
- 你本机的 CUDA 和你的 pytorch 版本是不是一致
- 上文提到的 requirements.txt 中文件末尾无用的行有没有删掉

如果完成了上述的两部检查，那么按照本教程重新快速部署一次环境，即可正常使用。

# 体验

下面我们就可以愉快的玩耍了。里面还有很多好玩的内容，可以参考官方的 [WIKI](https://github.com/oobabooga/text-generation-webui/wiki) 教程进一步定制化。
![image.png](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/c592880b0f4b460ba382ca39b5c57f14~tplv-73owjymdk6-watermark.image?policy=eyJ2bSI6MywidWlkIjoiNTM2MjE3NDA1ODk1MTQ5In0%3D&rk3s=e9ecf3d6&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1720668224&x-orig-sign=jW%2FUmjoJ3vwSyRh%2FiOeH8HhqAjg%3D)

# 参考

- https://github.com/oobabooga/text-generation-webui
- https://pytorch.org/get-started/locally/
- https://github.com/oobabooga/text-generation-webui/wiki
 