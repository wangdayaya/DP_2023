## 实现简单的线性回归模型


	import tensorflow as tf
	import numpy as np
	
	x = np.random.rand(100)
	y = 0.1 * x + 0.3
	w = tf.Variable(0.0)
	b = tf.Variable(0.0)
	predict = w * x + b
	loss = tf.reduce_mean(tf.square(y - predict)) # 计算损失
	opt = tf.train.GradientDescentOptimizer(0.1).minimize(loss) # 优化器
	init = tf.global_variables_initializer() # 初始化所有变量
	with tf.Session() as sess:
	    sess.run(init)
	    print(sess.run([w, b, loss]))
	    for n in range(200):
	        sess.run(opt)
	        print(n, sess.run([w, b, loss]))
	     
## 输出结果
 
	 [0.0, 0.0, 0.123262346]
	0 [0.036493912, 0.07001026, 0.068819314]
	1 [0.06362097, 0.12236534, 0.038450554]
	2 [0.08375389, 0.1615339, 0.021509996]
	3 [0.098664716, 0.1908534, 0.012059446]
	4 [0.109676875, 0.21281639, 0.0067867124]
	5 [0.117778756, 0.22928444, 0.0038443105]
	6 [0.12370851, 0.24164785, 0.0022017548]
	7 [0.1280174, 0.250945, 0.0012842582]
	8 [0.13111714, 0.25795138, 0.00077121536]
	9 [0.13331518, 0.2632462, 0.00048379667]
	10 [0.13484113, 0.26726204, 0.0003222565]
	11 [0.13586646, 0.27032194, 0.000230957]
	12 [0.13651922, 0.27266723, 0.00017886281]
	13 [0.13689502, 0.2744781, 0.00014866378]
	14 [0.13706525, 0.2758892, 0.00013070334]
	15 [0.13708323, 0.27700102, 0.00011959463]
	16 [0.13698876, 0.2778887, 0.0001123328]
	17 [0.13681152, 0.27860826, 0.00010724097]
	18 [0.13657372, 0.2792017, 0.0001033831]
	19 [0.13629188, 0.27970022, 0.00010023694]
	20 [0.13597836, 0.28012726, 9.751048e-05]
	21 [0.13564235, 0.2805003, 9.504009e-05]
	22 [0.13529071, 0.28083235, 9.273436e-05]
	23 [0.13492857, 0.28113317, 9.054168e-05]
	24 [0.1345597, 0.2814101, 8.843264e-05]
	25 [0.13418697, 0.28166857, 8.639051e-05]
	26 [0.13381244, 0.28191265, 8.4405445e-05]
	27 [0.1334377, 0.2821454, 8.247163e-05]
	28 [0.13306387, 0.28236914, 8.0585116e-05]
	29 [0.1326918, 0.28258553, 7.874349e-05]
	30 [0.13232212, 0.28279588, 7.694495e-05]
	31 [0.13195528, 0.28300118, 7.5188036e-05]
	32 [0.1315916, 0.28320214, 7.347148e-05]
	33 [0.13123131, 0.2833993, 7.1794326e-05]
	34 [0.13087456, 0.28359312, 7.015554e-05]
	35 [0.13052148, 0.28378388, 6.8554196e-05]
	36 [0.13017212, 0.28397182, 6.698951e-05]
	37 [0.12982652, 0.28415716, 6.5460474e-05]
	38 [0.1294847, 0.28434002, 6.396633e-05]
	39 [0.12914667, 0.28452054, 6.250627e-05]
	40 [0.12881242, 0.28469878, 6.107958e-05]
	41 [0.12848192, 0.28487483, 5.9685473e-05]
	42 [0.12815517, 0.28504875, 5.8323156e-05]
	43 [0.12783213, 0.2852206, 5.699198e-05]
	44 [0.12751277, 0.2853904, 5.5691205e-05]
	45 [0.12719704, 0.28555822, 5.4420092e-05]
	46 [0.12688492, 0.28572407, 5.317796e-05]
	47 [0.12657638, 0.28588802, 5.1964253e-05]
	48 [0.12627137, 0.28605005, 5.0778166e-05]
	49 [0.12596984, 0.2862102, 4.961919e-05]
	50 [0.12567177, 0.28636852, 4.8486676e-05]
	51 [0.12537712, 0.286525, 4.7379974e-05]
	52 [0.12508585, 0.2866797, 4.629855e-05]
	53 [0.12479792, 0.2868326, 4.52418e-05]
	54 [0.12451329, 0.28698376, 4.4209195e-05]
	55 [0.12423193, 0.28713316, 4.3200143e-05]
	56 [0.12395379, 0.28728086, 4.2214113e-05]
	57 [0.12367885, 0.28742686, 4.1250583e-05]
	58 [0.12340706, 0.28757116, 4.0309067e-05]
	59 [0.12313839, 0.28771383, 3.9389026e-05]
	60 [0.12287281, 0.28785485, 3.8490005e-05]
	61 [0.12261027, 0.28799427, 3.7611473e-05]
	62 [0.122350745, 0.28813207, 3.6753012e-05]
	63 [0.1220942, 0.2882683, 3.5914098e-05]
	64 [0.121840596, 0.28840294, 3.5094403e-05]
	65 [0.12158991, 0.28853604, 3.4293407e-05]
	66 [0.12134209, 0.28866762, 3.3510696e-05]
	67 [0.121097125, 0.2887977, 3.274581e-05]
	68 [0.120854974, 0.28892627, 3.1998417e-05]
	69 [0.1206156, 0.28905338, 3.126808e-05]
	70 [0.12037898, 0.28917903, 3.0554427e-05]
	71 [0.12014507, 0.28930324, 2.9857023e-05]
	72 [0.11991384, 0.28942603, 2.9175524e-05]
	73 [0.11968526, 0.28954738, 2.8509638e-05]
	74 [0.119459316, 0.28966737, 2.78589e-05]
	75 [0.11923596, 0.28978595, 2.7223055e-05]
	76 [0.11901517, 0.2899032, 2.6601716e-05]
	77 [0.118796915, 0.2900191, 2.5994535e-05]
	78 [0.11858116, 0.29013366, 2.5401205e-05]
	79 [0.11836789, 0.2902469, 2.482146e-05]
	80 [0.11815706, 0.29035884, 2.4254921e-05]
	81 [0.11794865, 0.2904695, 2.3701328e-05]
	82 [0.117742635, 0.2905789, 2.3160354e-05]
	83 [0.11753898, 0.29068702, 2.2631744e-05]
	84 [0.11733767, 0.29079393, 2.2115191e-05]
	85 [0.11713866, 0.2908996, 2.1610376e-05]
	86 [0.116941944, 0.29100406, 2.1117141e-05]
	87 [0.11674748, 0.29110733, 2.0635147e-05]
	88 [0.11655525, 0.2912094, 2.0164156e-05]
	89 [0.116365224, 0.29131028, 1.9703932e-05]
	90 [0.11617738, 0.29141003, 1.925419e-05]
	91 [0.1159917, 0.29150862, 1.8814735e-05]
	92 [0.115808144, 0.29160607, 1.8385324e-05]
	93 [0.1156267, 0.29170242, 1.796568e-05]
	94 [0.115447335, 0.29179767, 1.7555612e-05]
	95 [0.115270026, 0.2918918, 1.715492e-05]
	96 [0.11509476, 0.2919849, 1.6763366e-05]
	97 [0.1149215, 0.2920769, 1.6380745e-05]
	98 [0.11475023, 0.2921678, 1.6006885e-05]
	99 [0.11458093, 0.29225773, 1.5641523e-05]
	100 [0.11441357, 0.2923466, 1.528451e-05]
	101 [0.11424813, 0.29243445, 1.49356365e-05]
	102 [0.11408459, 0.2925213, 1.4594748e-05]
	103 [0.11392292, 0.29260713, 1.426163e-05]
	104 [0.11376311, 0.29269198, 1.39361255e-05]
	105 [0.113605134, 0.29277587, 1.3618041e-05]
	106 [0.11344897, 0.29285878, 1.3307216e-05]
	107 [0.1132946, 0.29294074, 1.3003482e-05]
	108 [0.113142006, 0.29302177, 1.2706698e-05]
	109 [0.11299116, 0.29310188, 1.2416672e-05]
	110 [0.112842046, 0.29318106, 1.2133242e-05]
	111 [0.11269464, 0.29325932, 1.18563175e-05]
	112 [0.11254893, 0.2933367, 1.1585707e-05]
	113 [0.1124049, 0.29341316, 1.1321274e-05]
	114 [0.11226252, 0.29348877, 1.1062885e-05]
	115 [0.11212177, 0.29356351, 1.0810371e-05]
	116 [0.11198263, 0.2936374, 1.0563613e-05]
	117 [0.11184509, 0.2937104, 1.0322523e-05]
	118 [0.11170913, 0.2937826, 1.0086936e-05]
	119 [0.11157474, 0.29385397, 9.8567e-06]
	120 [0.11144188, 0.2939245, 9.631723e-06]
	121 [0.11131055, 0.29399425, 9.411883e-06]
	122 [0.11118072, 0.29406318, 9.197052e-06]
	123 [0.11105239, 0.29413134, 8.98712e-06]
	124 [0.110925525, 0.2941987, 8.781993e-06]
	125 [0.110800125, 0.29426527, 8.581563e-06]
	126 [0.11067616, 0.2943311, 8.385694e-06]
	127 [0.11055362, 0.29439616, 8.1943035e-06]
	128 [0.11043249, 0.29446048, 8.00729e-06]
	129 [0.110312745, 0.29452407, 7.82452e-06]
	130 [0.11019438, 0.29458693, 7.645926e-06]
	131 [0.110077366, 0.29464906, 7.4714108e-06]
	132 [0.109961696, 0.2947105, 7.300879e-06]
	133 [0.10984735, 0.2947712, 7.134231e-06]
	134 [0.10973432, 0.29483122, 6.9714024e-06]
	135 [0.10962259, 0.29489055, 6.812276e-06]
	136 [0.10951214, 0.2949492, 6.656797e-06]
	137 [0.10940296, 0.29500717, 6.504856e-06]
	138 [0.10929503, 0.29506448, 6.3563807e-06]
	139 [0.10918834, 0.29512113, 6.2113077e-06]
	140 [0.10908288, 0.29517713, 6.0695347e-06]
	141 [0.10897862, 0.29523247, 5.9309987e-06]
	142 [0.108875565, 0.2952872, 5.795639e-06]
	143 [0.10877369, 0.29534128, 5.663354e-06]
	144 [0.10867299, 0.29539475, 5.5341025e-06]
	145 [0.108573444, 0.29544762, 5.4077873e-06]
	146 [0.10847504, 0.29549986, 5.284357e-06]
	147 [0.10837776, 0.2955515, 5.163759e-06]
	148 [0.108281605, 0.29560256, 5.0459053e-06]
	149 [0.10818655, 0.29565305, 4.9307273e-06]
	150 [0.10809258, 0.29570293, 4.818186e-06]
	151 [0.1079997, 0.29575226, 4.70822e-06]
	152 [0.10790788, 0.295801, 4.600759e-06]
	153 [0.10781711, 0.2958492, 4.4957546e-06]
	154 [0.107727386, 0.29589686, 4.3931364e-06]
	155 [0.107638694, 0.29594395, 4.2928623e-06]
	156 [0.107551016, 0.2959905, 4.1948865e-06]
	157 [0.10746434, 0.2960365, 4.099149e-06]
	158 [0.10737867, 0.29608202, 4.0055806e-06]
	159 [0.10729398, 0.296127, 3.914149e-06]
	160 [0.107210256, 0.29617146, 3.8248086e-06]
	161 [0.107127495, 0.2962154, 3.737515e-06]
	162 [0.10704569, 0.29625884, 3.6522126e-06]
	163 [0.10696482, 0.29630178, 3.5688493e-06]
	164 [0.106884874, 0.29634422, 3.4873904e-06]
	165 [0.106805846, 0.29638618, 3.4077973e-06]
	166 [0.10672773, 0.29642767, 3.3300112e-06]
	167 [0.10665051, 0.29646868, 3.254007e-06]
	168 [0.10657417, 0.2965092, 3.1797304e-06]
	169 [0.10649871, 0.29654926, 3.1071615e-06]
	170 [0.106424116, 0.29658887, 3.0362448e-06]
	171 [0.10635038, 0.29662803, 2.966934e-06]
	172 [0.10627749, 0.29666674, 2.8992158e-06]
	173 [0.10620543, 0.296705, 2.8330326e-06]
	174 [0.106134206, 0.29674283, 2.7683761e-06]
	175 [0.1060638, 0.2967802, 2.7051988e-06]
	176 [0.105994195, 0.29681715, 2.6434468e-06]
	177 [0.105925396, 0.2968537, 2.5831096e-06]
	178 [0.10585739, 0.2968898, 2.5241563e-06]
	179 [0.10579015, 0.29692551, 2.4665362e-06]
	180 [0.105723694, 0.2969608, 2.4102444e-06]
	181 [0.105657995, 0.29699567, 2.3552375e-06]
	182 [0.105593055, 0.29703015, 2.3014877e-06]
	183 [0.10552886, 0.29706424, 2.248956e-06]
	184 [0.1054654, 0.29709795, 2.197621e-06]
	185 [0.10540266, 0.29713127, 2.1474566e-06]
	186 [0.10534065, 0.2971642, 2.09844e-06]
	187 [0.10527935, 0.29719675, 2.050542e-06]
	188 [0.10521875, 0.29722893, 2.0037442e-06]
	189 [0.10515885, 0.29726073, 1.9579954e-06]
	190 [0.10509963, 0.29729217, 1.9133122e-06]
	191 [0.1050411, 0.29732326, 1.8696431e-06]
	192 [0.10498324, 0.29735398, 1.826967e-06]
	193 [0.10492604, 0.29738435, 1.7852665e-06]
	194 [0.1048695, 0.29741436, 1.7445199e-06]
	195 [0.104813606, 0.29744405, 1.7047042e-06]
	196 [0.10475835, 0.29747337, 1.6658008e-06]
	197 [0.10470374, 0.29750237, 1.6277828e-06]
	198 [0.10464975, 0.29753104, 1.5906227e-06]
	199 [0.104596384, 0.29755938, 1.5543271e-06]
	        
## 本文参考
本文参考：https://blog.csdn.net/qq_19672707/article/details/105236091